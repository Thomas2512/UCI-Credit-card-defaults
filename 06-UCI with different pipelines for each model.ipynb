{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- \n",
    "# UCI - Default from Credit Card Clients\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Dataset presentation\n",
    "\n",
    "This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n",
    "It can be found here:\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "There are 25 variables:\n",
    "\n",
    "* ID: ID of each client\n",
    "* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "* SEX: Gender (1=male, 2=female)\n",
    "* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "* AGE: Age in years\n",
    "* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
    "* PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "* PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "* PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "* PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "* PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
    "* default.payment.next.month: Default payment (1=yes, 0=no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Useful imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproecssing imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\usr\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Scripts',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\condabin',\n",
       " 'C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin',\n",
       " 'C:\\\\ProgramData\\\\Oracle\\\\Java\\\\javapath',\n",
       " 'C:\\\\WINDOWS\\\\system32',\n",
       " 'C:\\\\WINDOWS',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\Wbem',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0',\n",
       " 'C:\\\\Program Files\\\\PuTTY',\n",
       " 'C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin',\n",
       " 'C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon',\n",
       " 'C:\\\\Program Files\\\\Git LFS',\n",
       " 'C:\\\\Program Files\\\\Pandoc',\n",
       " 'C:\\\\Program Files\\\\MiKTeX 2.9\\\\miktex\\\\bin\\\\x64',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\usr\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Scripts',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Programs\\\\Git\\\\cmd',\n",
       " 'C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin',\n",
       " 'C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon',\n",
       " 'C:\\\\Users\\\\twang\\\\Downloads\\\\Portable\\\\npp.7.7.1.bin.x64',\n",
       " 'C:\\\\Program Files\\\\MiKTeX 2.9\\\\miktex\\\\bin\\\\x64',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PATH'].split(';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our Data easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'UCI_Credit_Card.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.load import load_raw_data\n",
    "from dataprep.load import load_data\n",
    "from dataprep.load import load_data_xy\n",
    "\n",
    "\n",
    "df = load_data(path)\n",
    "X_raw, y_raw = load_data_xy(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our train/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting our Df into test/train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(df, \n",
    "                                    test_size=6000, \n",
    "                                    stratify=df.default, \n",
    "                                    random_state=42)\n",
    "df_train, df_test = train_test_split(df_train, \n",
    "                                     test_size=6000, \n",
    "                                     stratify=df_train.default, \n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.load import df2xy\n",
    "\n",
    "X_train, y_train = df2xy(df_train, 'default')\n",
    "X_test, y_test = df2xy(df_test, 'default')\n",
    "X_val, y_val = df2xy(df_val, 'default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol for pipelined workflow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# * Pipeline for lowercasing\n",
    "* pipeline for re-labelling the mislabelled data\n",
    "\n",
    "* pipe for ageBins\n",
    "* pipe for gender x Marriage\n",
    "* pipe for gender x age\n",
    "* pipe for next month's bill\n",
    "---> One output: X_cat, que l'on normalise avec pipe=StandardScaler\n",
    "* pipe for 1-hot\n",
    "* pipe for scaling\n",
    "---> We get our second output X_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on se doit de définir les dictionnaires / classes que l'on va utiliser pour stocker les modèles, leurs scores selon toutes les métriques"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "models = []\n",
    "models.append(LogisticReg...)\n",
    "\n",
    "scores_accuracy={}\n",
    "scores_recall\n",
    "scores_auc\n",
    "features_importances={}\n",
    "chacun de ces dictionnaires contenant les performances du modèle: {'test': score_test, 'train': score_train}\n",
    "for model in models:\n",
    "    scores_accuracy{[model][train]} = accuracy_score(model.predict(X_test), y_test)\n",
    "    scores_accuracy{[model][test]} = accuracy(model.predict(X_train), y_train)\n",
    "    idem for recall, auc...\n",
    "    features_importances[model] = features_importanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, on pourra les capitalizer facilement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementary Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementary Pipelines are Pipelines that only do a little processing, such as adding / removing a single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementary Transformers from Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data by age group\n",
    "from dataprep.pipelines import AgeBinAdder\n",
    "# Gender x Marriage new category\n",
    "from dataprep.pipelines import GenderXMarriageAdder\n",
    "# Gender x AgeBin new category\n",
    "from dataprep.pipelines import GenderXAgeBinAdder\n",
    "# Predict next month's bill statement\n",
    "from dataprep.pipelines import NextBillAdder\n",
    "# Get_dummies to Df\n",
    "from dataprep.pipelines import CategoricalWarrior\n",
    "# Drop a column\n",
    "from dataprep.pipelines import ColumnDropper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the different classifiers that we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_models['log'] = log_clf = LogisticRegression(C=0.1, \n",
    "                             solver='liblinear',\n",
    "                             penalty='l2',\n",
    "                             class_weight='balanced', \n",
    "                             random_state=42, \n",
    "                             n_jobs=-1)\n",
    "dico_models['svm'] =  SVC(gamma='auto', C=1, class_weight='balanced')\n",
    "dico_models['tree'] = DecisionTreeClassifier(criterion='entropy', \n",
    "                                  random_state=42, \n",
    "                                 max_leaf_nodes=5,\n",
    "                                 class_weight='balanced')\n",
    "dico_models['forest'] = RandomForestClassifier(n_estimators=500, \n",
    "                                 max_leaf_nodes=10, \n",
    "                                 n_jobs=-1, \n",
    "                                 class_weight='balanced',\n",
    "                                random_state=42)\n",
    "\n",
    "dico_models['adaboost'] = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_models['xgboost'] = xgb.XGBClassifier(scale_pos_weight=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Pipelines consists of the following architecture:  \n",
    "  [Complex Pipeline, Classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dico_pipelined_models_num = defaultdict(dict)\n",
    "dico_pipelined_models_cat = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining which preprocessing pipelines we should use, for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_appropriate_preproc = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_appropriate_preproc['log'] = []\n",
    "\n",
    "dico_appropriate_preproc['log'].append( make_pipeline(StandardScaler()) )\n",
    "dico_appropriate_preproc['log'].append( make_pipeline(NextBillAdder(), \n",
    "                                                      StandardScaler()) )\n",
    "dico_appropriate_preproc['log'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']) ) )\n",
    "dico_appropriate_preproc['log'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']),\n",
    "                                                      StandardScaler()) )\n",
    "dico_appropriate_preproc['log'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']) ) ) \n",
    "dico_appropriate_preproc['log'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']), \n",
    "                                                      StandardScaler()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_appropriate_preproc['svm'] = []\n",
    "\n",
    "dico_appropriate_preproc['svm'].append( make_pipeline(StandardScaler()) )\n",
    "dico_appropriate_preproc['svm'].append( make_pipeline(NextBillAdder(), \n",
    "                                                      StandardScaler()) )\n",
    "dico_appropriate_preproc['svm'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']), \n",
    "                                                      StandardScaler()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_appropriate_preproc['tree'] = []\n",
    "\n",
    "dico_appropriate_preproc['tree'].append( make_pipeline(StandardScaler()) )\n",
    "dico_appropriate_preproc['tree'].append( make_pipeline(NextBillAdder(), \n",
    "                                                      StandardScaler()) )\n",
    "dico_appropriate_preproc['tree'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']) ) )\n",
    "dico_appropriate_preproc['tree'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']) ) ) \n",
    "dico_appropriate_preproc['tree'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']), \n",
    "                                                      StandardScaler()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_appropriate_preproc['forest'] = []\n",
    "\n",
    "dico_appropriate_preproc['forest'].append( make_pipeline(StandardScaler()) )\n",
    "dico_appropriate_preproc['forest'].append( make_pipeline(NextBillAdder(), \n",
    "                                                      StandardScaler()) )\n",
    "dico_appropriate_preproc['forest'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']) ) )\n",
    "dico_appropriate_preproc['forest'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']) ) ) \n",
    "dico_appropriate_preproc['forest'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']), \n",
    "                                                      StandardScaler()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It overfits the majority class 'default' too much, let's stop experimenting on it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_appropriate_preproc['xgboost'] = []\n",
    "\n",
    "dico_appropriate_preproc['xgboost'].append( make_pipeline(StandardScaler()) )\n",
    "dico_appropriate_preproc['xgboost'].append( make_pipeline(NextBillAdder(), \n",
    "                                                      StandardScaler()) )\n",
    "dico_appropriate_preproc['xgboost'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']) ) )\n",
    "dico_appropriate_preproc['xgboost'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']) ) ) \n",
    "dico_appropriate_preproc['xgboost'].append( make_pipeline(AgeBinAdder(), \n",
    "                                                      GenderXAgeBinAdder(), \n",
    "                                                      GenderXMarriageAdder(), \n",
    "                                                      NextBillAdder(), \n",
    "                                                      ColumnDropper('age'), \n",
    "                                                      CategoricalWarrior(['gender', 'education', 'marriage']), \n",
    "                                                      StandardScaler()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining all the Prediction Pipelines to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_pipelined_models_num = defaultdict(dict)\n",
    "\n",
    "for (name, model) in dico_models.items():\n",
    "#     print(name)\n",
    "    for (i, complex_pipe) in enumerate(dico_appropriate_preproc[name]):\n",
    "#         print(i)\n",
    "        dico_pipelined_models_num[name][i] = Pipeline([\n",
    "            ('preproc', complex_pipe),\n",
    "            ('classifier', model)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'log': {0: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                                  fit_intercept=True, intercept_scaling=1,\n",
       "                                                  l1_ratio=None, max_iter=100,\n",
       "                                                  multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                                  random_state=42, solver='liblinear',\n",
       "                                                  tol=0.0001, verbose=0, warm_start=False))],\n",
       "                       verbose=False), 1: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('nextbilladder', NextBillAdder()),\n",
       "                                               ('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                                  fit_intercept=True, intercept_scaling=1,\n",
       "                                                  l1_ratio=None, max_iter=100,\n",
       "                                                  multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                                  random_state=42, solver='liblinear',\n",
       "                                                  tol=0.0001, verbose=0, warm_start=False))],\n",
       "                       verbose=False), 2: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'marriage']))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                                  fit_intercept=True, intercept_scaling=1,\n",
       "                                                  l1_ratio=None, max_iter=100,\n",
       "                                                  multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                                  random_state=42, solver='liblinear',\n",
       "                                                  tol=0.0001, verbose=0, warm_start=False))],\n",
       "                       verbose=False), 3: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'marriage'])),\n",
       "                                               ('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                                  fit_intercept=True, intercept_scaling=1,\n",
       "                                                  l1_ratio=None, max_iter=100,\n",
       "                                                  multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                                  random_state=42, solver='liblinear',\n",
       "                                                  tol=0.0001, verbose=0, warm_start=False))],\n",
       "                       verbose=False), 4: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'marriage']))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                                  fit_intercept=True, intercept_scaling=1,\n",
       "                                                  l1_ratio=None, max_iter=100,\n",
       "                                                  multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                                  random_state=42, solver='liblinear',\n",
       "                                                  tol=0.0001, verbose=0, warm_start=False))],\n",
       "                       verbose=False), 5: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'm...\n",
       "                                               ('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                                  fit_intercept=True, intercept_scaling=1,\n",
       "                                                  l1_ratio=None, max_iter=100,\n",
       "                                                  multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                                  random_state=42, solver='liblinear',\n",
       "                                                  tol=0.0001, verbose=0, warm_start=False))],\n",
       "                       verbose=False)}, 'svm': {0: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "                                   decision_function_shape='ovr', degree=3, gamma='auto',\n",
       "                                   kernel='rbf', max_iter=-1, probability=False,\n",
       "                                   random_state=None, shrinking=True, tol=0.001,\n",
       "                                   verbose=False))],\n",
       "                       verbose=False), 1: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('nextbilladder', NextBillAdder()),\n",
       "                                               ('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "                                   decision_function_shape='ovr', degree=3, gamma='auto',\n",
       "                                   kernel='rbf', max_iter=-1, probability=False,\n",
       "                                   random_state=None, shrinking=True, tol=0.001,\n",
       "                                   verbose=False))],\n",
       "                       verbose=False), 2: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'marriage'])),\n",
       "                                               ('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "                                   decision_function_shape='ovr', degree=3, gamma='auto',\n",
       "                                   kernel='rbf', max_iter=-1, probability=False,\n",
       "                                   random_state=None, shrinking=True, tol=0.001,\n",
       "                                   verbose=False))],\n",
       "                       verbose=False)}, 'tree': {0: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                      criterion='entropy', max_depth=None,\n",
       "                                                      max_features=None, max_leaf_nodes=5,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      presort=False, random_state=42,\n",
       "                                                      splitter='best'))],\n",
       "                       verbose=False), 1: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('nextbilladder', NextBillAdder()),\n",
       "                                               ('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                      criterion='entropy', max_depth=None,\n",
       "                                                      max_features=None, max_leaf_nodes=5,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      presort=False, random_state=42,\n",
       "                                                      splitter='best'))],\n",
       "                       verbose=False), 2: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'marriage']))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                      criterion='entropy', max_depth=None,\n",
       "                                                      max_features=None, max_leaf_nodes=5,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      presort=False, random_state=42,\n",
       "                                                      splitter='best'))],\n",
       "                       verbose=False), 3: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'marriage']))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                      criterion='entropy', max_depth=None,\n",
       "                                                      max_features=None, max_leaf_nodes=5,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      presort=False, random_state=42,\n",
       "                                                      splitter='best'))],\n",
       "                       verbose=False), 4: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'm...\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                      criterion='entropy', max_depth=None,\n",
       "                                                      max_features=None, max_leaf_nodes=5,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      presort=False, random_state=42,\n",
       "                                                      splitter='best'))],\n",
       "                       verbose=False)}, 'forest': {0: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                                      criterion='gini', max_depth=None,\n",
       "                                                      max_features='auto', max_leaf_nodes=10,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      n_estimators=500, n_jobs=-1,\n",
       "                                                      oob_score=False, random_state=42,\n",
       "                                                      verbose=0, warm_start=False))],\n",
       "                       verbose=False), 1: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('nextbilladder', NextBillAdder()),\n",
       "                                               ('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                                      criterion='gini', max_depth=None,\n",
       "                                                      max_features='auto', max_leaf_nodes=10,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      n_estimators=500, n_jobs=-1,\n",
       "                                                      oob_score=False, random_state=42,\n",
       "                                                      verbose=0, warm_start=False))],\n",
       "                       verbose=False), 2: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'marriage']))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                                      criterion='gini', max_depth=None,\n",
       "                                                      max_features='auto', max_leaf_nodes=10,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      n_estimators=500, n_jobs=-1,\n",
       "                                                      oob_score=False, random_state=42,\n",
       "                                                      verbose=0, warm_start=False))],\n",
       "                       verbose=False), 3: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'm...\n",
       "                               RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                                      criterion='gini', max_depth=None,\n",
       "                                                      max_features='auto', max_leaf_nodes=10,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      n_estimators=500, n_jobs=-1,\n",
       "                                                      oob_score=False, random_state=42,\n",
       "                                                      verbose=0, warm_start=False))],\n",
       "                       verbose=False), 4: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'm...\n",
       "                               RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                                      criterion='gini', max_depth=None,\n",
       "                                                      max_features='auto', max_leaf_nodes=10,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      n_estimators=500, n_jobs=-1,\n",
       "                                                      oob_score=False, random_state=42,\n",
       "                                                      verbose=0, warm_start=False))],\n",
       "                       verbose=False)}, 'xgboost': {0: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                             colsample_bylevel=1, colsample_bynode=1,\n",
       "                                             colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                                             max_delta_step=0, max_depth=3,\n",
       "                                             min_child_weight=1, missing=None,\n",
       "                                             n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                             objective='binary:logistic', random_state=0,\n",
       "                                             reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "                                             seed=None, silent=None, subsample=1,\n",
       "                                             verbosity=1))],\n",
       "                       verbose=False), 1: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('nextbilladder', NextBillAdder()),\n",
       "                                               ('standardscaler',\n",
       "                                                StandardScaler(copy=True, with_mean=True,\n",
       "                                                               with_std=True))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                             colsample_bylevel=1, colsample_bynode=1,\n",
       "                                             colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                                             max_delta_step=0, max_depth=3,\n",
       "                                             min_child_weight=1, missing=None,\n",
       "                                             n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                             objective='binary:logistic', random_state=0,\n",
       "                                             reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "                                             seed=None, silent=None, subsample=1,\n",
       "                                             verbosity=1))],\n",
       "                       verbose=False), 2: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'marriage']))],\n",
       "                                        verbose=False)),\n",
       "                              ('classifier',\n",
       "                               XGB...ooster='gbtree',\n",
       "                                             colsample_bylevel=1, colsample_bynode=1,\n",
       "                                             colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                                             max_delta_step=0, max_depth=3,\n",
       "                                             min_child_weight=1, missing=None,\n",
       "                                             n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                             objective='binary:logistic', random_state=0,\n",
       "                                             reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "                                             seed=None, silent=None, subsample=1,\n",
       "                                             verbosity=1))],\n",
       "                       verbose=False), 3: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'm...\n",
       "                               XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                             colsample_bylevel=1, colsample_bynode=1,\n",
       "                                             colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                                             max_delta_step=0, max_depth=3,\n",
       "                                             min_child_weight=1, missing=None,\n",
       "                                             n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                             objective='binary:logistic', random_state=0,\n",
       "                                             reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "                                             seed=None, silent=None, subsample=1,\n",
       "                                             verbosity=1))],\n",
       "                       verbose=False), 4: Pipeline(memory=None,\n",
       "                       steps=[('preproc',\n",
       "                               Pipeline(memory=None,\n",
       "                                        steps=[('agebinadder', AgeBinAdder()),\n",
       "                                               ('genderxagebinadder', GenderXAgeBinAdder()),\n",
       "                                               ('genderxmarriageadder',\n",
       "                                                GenderXMarriageAdder()),\n",
       "                                               ('nextbilladder', NextBillAdder()),\n",
       "                                               ('columndropper', ColumnDropper(column='age')),\n",
       "                                               ('categoricalwarrior',\n",
       "                                                CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                                    'education',\n",
       "                                                                                    'm...\n",
       "                               XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                             colsample_bylevel=1, colsample_bynode=1,\n",
       "                                             colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                                             max_delta_step=0, max_depth=3,\n",
       "                                             min_child_weight=1, missing=None,\n",
       "                                             n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                             objective='binary:logistic', random_state=0,\n",
       "                                             reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "                                             seed=None, silent=None, subsample=1,\n",
       "                                             verbosity=1))],\n",
       "                       verbose=False)}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_pipelined_models_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training all the Prediction Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_classification_reports = defaultdict(dict)\n",
    "dico_confusion_matrices = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 0, Log\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      4673\n",
      "           1       0.48      0.57      0.52      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.78      0.77      0.78      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 1, Log\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      4673\n",
      "           1       0.48      0.57      0.52      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.78      0.77      0.78      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 2, Log\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.51      0.64      4673\n",
      "           1       0.29      0.71      0.41      1327\n",
      "\n",
      "    accuracy                           0.56      6000\n",
      "   macro avg       0.58      0.61      0.53      6000\n",
      "weighted avg       0.74      0.56      0.59      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 3, Log\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      4673\n",
      "           1       0.49      0.57      0.53      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.79      0.77      0.78      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 4, Log\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      4673\n",
      "           1       0.33      0.37      0.34      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.57      0.58      0.57      6000\n",
      "weighted avg       0.71      0.69      0.70      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 5, Log\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      4673\n",
      "           1       0.49      0.57      0.53      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.79      0.77      0.78      6000\n",
      "\n",
      "SVM\n",
      "-------------\n",
      "Pipe 0, Svm\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84      4673\n",
      "           1       0.46      0.59      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "Pipe 1, Svm\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84      4673\n",
      "           1       0.46      0.59      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "Pipe 2, Svm\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      4673\n",
      "           1       0.46      0.58      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "TREE\n",
      "-------------\n",
      "Pipe 0, Tree\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      4673\n",
      "           1       0.48      0.54      0.51      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.69      0.68      6000\n",
      "weighted avg       0.78      0.77      0.77      6000\n",
      "\n",
      "Pipe 1, Tree\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      4673\n",
      "           1       0.48      0.54      0.51      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.69      0.68      6000\n",
      "weighted avg       0.78      0.77      0.77      6000\n",
      "\n",
      "Pipe 2, Tree\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      4673\n",
      "           1       0.48      0.54      0.51      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.69      0.68      6000\n",
      "weighted avg       0.78      0.77      0.77      6000\n",
      "\n",
      "Pipe 3, Tree\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      4673\n",
      "           1       0.48      0.54      0.51      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.69      0.68      6000\n",
      "weighted avg       0.78      0.77      0.77      6000\n",
      "\n",
      "Pipe 4, Tree\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      4673\n",
      "           1       0.48      0.54      0.51      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.69      0.68      6000\n",
      "weighted avg       0.78      0.77      0.77      6000\n",
      "\n",
      "FOREST\n",
      "-------------\n",
      "Pipe 0, Forest\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      4673\n",
      "           1       0.46      0.60      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "Pipe 1, Forest\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      4673\n",
      "           1       0.46      0.61      0.53      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.79      0.76      0.77      6000\n",
      "\n",
      "Pipe 2, Forest\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      4673\n",
      "           1       0.46      0.62      0.53      1327\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.67      0.71      0.68      6000\n",
      "weighted avg       0.79      0.75      0.77      6000\n",
      "\n",
      "Pipe 3, Forest\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      4673\n",
      "           1       0.46      0.62      0.53      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.71      0.68      6000\n",
      "weighted avg       0.79      0.76      0.77      6000\n",
      "\n",
      "Pipe 4, Forest\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      4673\n",
      "           1       0.46      0.61      0.53      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.71      0.68      6000\n",
      "weighted avg       0.79      0.76      0.77      6000\n",
      "\n",
      "ADABOOST\n",
      "-------------\n",
      "XGBOOST\n",
      "-------------\n",
      "Pipe 0, Xgboost\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78      4673\n",
      "           1       0.40      0.73      0.51      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.65      0.71      0.65      6000\n",
      "weighted avg       0.79      0.69      0.72      6000\n",
      "\n",
      "Pipe 1, Xgboost\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.78      4673\n",
      "           1       0.39      0.72      0.51      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.64      0.70      0.64      6000\n",
      "weighted avg       0.79      0.69      0.72      6000\n",
      "\n",
      "Pipe 2, Xgboost\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.78      4673\n",
      "           1       0.39      0.72      0.51      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.65      0.70      0.64      6000\n",
      "weighted avg       0.79      0.69      0.72      6000\n",
      "\n",
      "Pipe 3, Xgboost\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78      4673\n",
      "           1       0.39      0.72      0.51      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.64      0.70      0.64      6000\n",
      "weighted avg       0.78      0.69      0.72      6000\n",
      "\n",
      "Pipe 4, Xgboost\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.77      4673\n",
      "           1       0.39      0.72      0.51      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.64      0.70      0.64      6000\n",
      "weighted avg       0.78      0.69      0.72      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (name, model) in dico_models.items():\n",
    "    print(name.upper())\n",
    "    print('-------------')\n",
    "    for (i, complex_pipe) in enumerate(dico_pipelined_models_num[name]):\n",
    "#         print('!!! POURQUOI CA MARCHE PAS !!!')\n",
    "        pipe = dico_pipelined_models_num[name][i]\n",
    "        pipe.fit(X_train, np.ravel(y_train))\n",
    "        print('Pipe {}, {}'.format(i, name.capitalize()))\n",
    "        print('----------------')\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        dico_classification_reports[name][i] = classification_report(y_test, y_pred)\n",
    "        dico_confusion_matrices[name][i] = confusion_matrix(y_test, y_pred)\n",
    "        print(dico_classification_reports[name][i])\n",
    "        #print(dico_confusion_matrices[i][name])\n",
    "\n",
    "#         print('!!! POURQUOI CA MARCHE PAS !!!')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic regression:  \n",
    "We have a great recall of our default class, using all our engineered features, as well as keeping our 'age' feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SVM:  \n",
    "Adding our previously engineered features leads to no change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decision Tree:  \n",
    "All the different preprocessing pipelines lead to similar results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest:  \n",
    "All the different preprocessing pipelines lead to similar results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost:  \n",
    "All the different preprocessing pipelines lead to similar results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, it seems that all our new features aren't too useful, excepted for the Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranked by performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the best (preprocessing, model) couples:   \n",
    "(best = best recall score on the default class, evaluated on the Test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classification_report(model_name, pipe_number):\n",
    "    print('{}, Pipe {}'.format(model_name.capitalize(), pipe_number))\n",
    "    print('----------------')\n",
    "    print(dico_classification_reports[model_name][pipe_number])\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log, Pipe 2\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.51      0.64      4673\n",
      "           1       0.29      0.71      0.41      1327\n",
      "\n",
      "    accuracy                           0.56      6000\n",
      "   macro avg       0.58      0.61      0.53      6000\n",
      "weighted avg       0.74      0.56      0.59      6000\n",
      "\n",
      "------------------------------------------------------\n",
      "Svm, Pipe 0\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84      4673\n",
      "           1       0.46      0.59      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "------------------------------------------------------\n",
      "Forest, Pipe 3\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      4673\n",
      "           1       0.46      0.62      0.53      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.71      0.68      6000\n",
      "weighted avg       0.79      0.76      0.77      6000\n",
      "\n",
      "------------------------------------------------------\n",
      "Xgboost, Pipe 1\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.78      4673\n",
      "           1       0.39      0.72      0.51      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.64      0.70      0.64      6000\n",
      "weighted avg       0.79      0.69      0.72      6000\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "show_classification_report('log', 2)\n",
    "show_classification_report('svm', 0)\n",
    "show_classification_report('forest', 3)\n",
    "show_classification_report('xgboost', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleurs modèles (en comparant selon le recall des default):\n",
    "* (XGBoost, 1): avec la prédiction du Next Bill\n",
    "* (Logistic Regression, 2):, avec toutes les features engineerées et sans Scaling (!)\n",
    "* (Random Forest, 3): (peu importe le type de preprocessing\n",
    "* (SVM, 0): (scalé absolument, avec ou sans Next Bill ^^ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning our best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO Next"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OK - SOVLED\n",
    "Careful!\n",
    "Log doesn't take categorical: complex_pipeline2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OK - DONE\n",
    "* Find a way to not explore all preprocessing pipelines for some models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OK - DONE\n",
    "* Use pipelines with XGBoost model (only the relevant Complex preprocessing pipelines ones!)\n",
    "ie: no need to scale"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* Use pipelines with LightGBM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* Fine-tuning our best prediction parameters, directly through the [preproc, prediction] pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
