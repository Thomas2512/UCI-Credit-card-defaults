{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- \n",
    "# UCI - Default from Credit Card Clients\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Dataset presentation\n",
    "\n",
    "This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n",
    "It can be found here:\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "There are 25 variables:\n",
    "\n",
    "* ID: ID of each client\n",
    "* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "* SEX: Gender (1=male, 2=female)\n",
    "* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "* AGE: Age in years\n",
    "* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
    "* PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "* PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "* PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "* PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "* PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
    "* default.payment.next.month: Default payment (1=yes, 0=no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Useful imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproecssing imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\usr\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Scripts',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\condabin',\n",
       " 'C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin',\n",
       " 'C:\\\\ProgramData\\\\Oracle\\\\Java\\\\javapath',\n",
       " 'C:\\\\WINDOWS\\\\system32',\n",
       " 'C:\\\\WINDOWS',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\Wbem',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0',\n",
       " 'C:\\\\Program Files\\\\PuTTY',\n",
       " 'C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin',\n",
       " 'C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon',\n",
       " 'C:\\\\Program Files\\\\Git LFS',\n",
       " 'C:\\\\Program Files\\\\Pandoc',\n",
       " 'C:\\\\Program Files\\\\MiKTeX 2.9\\\\miktex\\\\bin\\\\x64',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\usr\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Scripts',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Programs\\\\Git\\\\cmd',\n",
       " 'C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin',\n",
       " 'C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon',\n",
       " 'C:\\\\Users\\\\twang\\\\Downloads\\\\Portable\\\\npp.7.7.1.bin.x64',\n",
       " 'C:\\\\Program Files\\\\MiKTeX 2.9\\\\miktex\\\\bin\\\\x64',\n",
       " '.']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PATH'].split(';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our Data easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'UCI_Credit_Card.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.load import load_raw_data\n",
    "from dataprep.load import load_data\n",
    "from dataprep.load import load_data_xy\n",
    "\n",
    "\n",
    "df = load_data(path)\n",
    "X_raw, y_raw = load_data_xy(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our train/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting our Df into test/train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(df, \n",
    "                                    test_size=6000, \n",
    "                                    stratify=df.default, \n",
    "                                    random_state=42)\n",
    "df_train, df_test = train_test_split(df_train, \n",
    "                                     test_size=6000, \n",
    "                                     stratify=df_train.default, \n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.load import df2xy\n",
    "\n",
    "X_train, y_train = df2xy(df_train, 'default')\n",
    "X_test, y_test = df2xy(df_test, 'default')\n",
    "X_val, y_val = df2xy(df_val, 'default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol for pipelined workflow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# * Pipeline for lowercasing\n",
    "* pipeline for re-labelling the mislabelled data\n",
    "\n",
    "* pipe for ageBins\n",
    "* pipe for gender x Marriage\n",
    "* pipe for gender x age\n",
    "* pipe for next month's bill\n",
    "---> One output: X_cat, que l'on normalise avec pipe=StandardScaler\n",
    "* pipe for 1-hot\n",
    "* pipe for scaling\n",
    "---> We get our second output X_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on se doit de définir les dictionnaires / classes que l'on va utiliser pour stocker les modèles, leurs scores selon toutes les métriques"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "models = []\n",
    "models.append(LogisticReg...)\n",
    "\n",
    "scores_accuracy={}\n",
    "scores_recall\n",
    "scores_auc\n",
    "features_importances={}\n",
    "chacun de ces dictionnaires contenant les performances du modèle: {'test': score_test, 'train': score_train}\n",
    "for model in models:\n",
    "    scores_accuracy{[model][train]} = accuracy_score(model.predict(X_test), y_test)\n",
    "    scores_accuracy{[model][test]} = accuracy(model.predict(X_train), y_train)\n",
    "    idem for recall, auc...\n",
    "    features_importances[model] = features_importanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, on pourra les capitalizer facilement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementary Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementary Pipelines are Pipelines that only do a little processing, such as adding / removing a single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementary Transformers from Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data by age group\n",
    "from dataprep.pipelines import AgeBinAdder\n",
    "# Gender x Marriage new category\n",
    "from dataprep.pipelines import GenderXMarriageAdder\n",
    "# Gender x AgeBin new category\n",
    "from dataprep.pipelines import GenderXAgeBinAdder\n",
    "# Predict next month's bill statement\n",
    "from dataprep.pipelines import NextBillAdder\n",
    "# Get_dummies to Df\n",
    "from dataprep.pipelines import CategoricalWarrior\n",
    "# Drop a column\n",
    "from dataprep.pipelines import ColumnDropper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex Pipelines are combinations of multiple Elementary Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define them, and check that they work well below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_pipelines = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pipe_result(pipeline, df, n=2):\n",
    "    result = pipeline.fit_transform(df)\n",
    "    print(\"Shape: \", result.shape)\n",
    "    if isinstance(result, pd.DataFrame):\n",
    "        # We're using display, because the df doesn't show by itself when it's encapsulated in a function\n",
    "        display(result.head())\n",
    "    elif isinstance(result, np.ndarray):\n",
    "        print(result[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Scaler only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's scale the data, as our only data modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with a StandardScaler\n",
    "complex_pipe1 = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (30000, 23)\n",
      "[[-1.13672015  0.81016074  0.21186989 -1.06879721 -1.24601985  1.84394071\n",
      "   2.39995869 -0.40419908 -0.36400938 -0.33135449 -0.33818882 -0.64250107\n",
      "  -0.64739923 -0.66799331 -0.67249727 -0.66305853 -0.65272422 -0.34194162\n",
      "  -0.22708564 -0.29680127 -0.30806256 -0.31413612 -0.29338206]\n",
      " [-0.3659805   0.81016074  0.21186989  0.84913055 -1.02904717 -0.54231679\n",
      "   2.39995869 -0.40419908 -0.36400938 -0.33135449  2.956928   -0.65921875\n",
      "  -0.66674657 -0.63925429 -0.62163594 -0.60622927 -0.59796638 -0.34194162\n",
      "  -0.21358766 -0.24000461 -0.24422965 -0.31413612 -0.18087821]]\n"
     ]
    }
   ],
   "source": [
    "show_pipe_result(complex_pipe1, X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Next bill & Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the Next bill prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with a StandardScaler\n",
    "complex_pipe2 = Pipeline([\n",
    "    (\"next_bill\", NextBillAdder()),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (30000, 24)\n",
      "[[-1.13672015  0.81016074  0.21186989 -1.06879721 -1.24601985  1.84394071\n",
      "   2.39995869 -0.40419908 -0.36400938 -0.33135449 -0.33818882 -0.64250107\n",
      "  -0.64739923 -0.66799331 -0.67249727 -0.66305853 -0.65272422 -0.34194162\n",
      "  -0.22708564 -0.29680127 -0.30806256 -0.31413612 -0.29338206 -0.64264241]\n",
      " [-0.3659805   0.81016074  0.21186989  0.84913055 -1.02904717 -0.54231679\n",
      "   2.39995869 -0.40419908 -0.36400938 -0.33135449  2.956928   -0.65921875\n",
      "  -0.66674657 -0.63925429 -0.62163594 -0.60622927 -0.59796638 -0.34194162\n",
      "  -0.21358766 -0.24000461 -0.24422965 -0.31413612 -0.18087821 -0.65937279]]\n"
     ]
    }
   ],
   "source": [
    "show_pipe_result(complex_pipe2, X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With our 4 engineered features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's add our 4 feature engineering Elementary Pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_pipe3 = Pipeline([\n",
    "    (\"age_bin\", AgeBinAdder()),\n",
    "    (\"gender_age_bin\", GenderXAgeBinAdder()),\n",
    "    (\"gender_marriage\", GenderXMarriageAdder()),\n",
    "    (\"next_bill\", NextBillAdder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (30000, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_1</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>pay_5</th>\n",
       "      <th>pay_6</th>\n",
       "      <th>bill_amt1</th>\n",
       "      <th>bill_amt2</th>\n",
       "      <th>bill_amt3</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>gen_ageBin</th>\n",
       "      <th>gen_mar</th>\n",
       "      <th>pred_bill_amt0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20s</td>\n",
       "      <td>(2, 20s)</td>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>3909.683795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>20s</td>\n",
       "      <td>(2, 20s)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>2678.148995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>30s</td>\n",
       "      <td>(2, 30s)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>29177.529785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30s</td>\n",
       "      <td>(2, 30s)</td>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>46995.038110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>50s</td>\n",
       "      <td>(1, 50s)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>8605.584386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   limit_bal  gender  education  marriage  age  pay_1  pay_2  pay_3  pay_4  \\\n",
       "0    20000.0       2          2         1   24      1      1      0      0   \n",
       "1   120000.0       2          2         2   26      0      1      0      0   \n",
       "2    90000.0       2          2         2   34      0      0      0      0   \n",
       "3    50000.0       2          2         1   37      0      0      0      0   \n",
       "4    50000.0       1          2         1   57      0      0      0      0   \n",
       "\n",
       "   pay_5  pay_6  bill_amt1  bill_amt2  bill_amt3  bill_amt4  bill_amt5  \\\n",
       "0      0      0     3913.0     3102.0      689.0        0.0        0.0   \n",
       "1      0      1     2682.0     1725.0     2682.0     3272.0     3455.0   \n",
       "2      0      0    29239.0    14027.0    13559.0    14331.0    14948.0   \n",
       "3      0      0    46990.0    48233.0    49291.0    28314.0    28959.0   \n",
       "4      0      0     8617.0     5670.0    35835.0    20940.0    19146.0   \n",
       "\n",
       "   bill_amt6  pay_amt1  pay_amt2  pay_amt3  pay_amt4  pay_amt5  pay_amt6  \\\n",
       "0        0.0       0.0     689.0       0.0       0.0       0.0       0.0   \n",
       "1     3261.0       0.0    1000.0    1000.0    1000.0       0.0    2000.0   \n",
       "2    15549.0    1518.0    1500.0    1000.0    1000.0    1000.0    5000.0   \n",
       "3    29547.0    2000.0    2019.0    1200.0    1100.0    1069.0    1000.0   \n",
       "4    19131.0    2000.0   36681.0   10000.0    9000.0     689.0     679.0   \n",
       "\n",
       "  age_bin gen_ageBin gen_mar  pred_bill_amt0  \n",
       "0     20s   (2, 20s)  (2, 1)     3909.683795  \n",
       "1     20s   (2, 20s)  (2, 2)     2678.148995  \n",
       "2     30s   (2, 30s)  (2, 2)    29177.529785  \n",
       "3     30s   (2, 30s)  (2, 1)    46995.038110  \n",
       "4     50s   (1, 50s)  (1, 1)     8605.584386  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_pipe_result(complex_pipe3, X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With our 4 engineered features, but whithout 'age'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the 'age' feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_pipe4 = Pipeline([\n",
    "    (\"age_bin\", AgeBinAdder()),\n",
    "    (\"gender_age_bin\", GenderXAgeBinAdder()),\n",
    "    (\"gender_marriage\", GenderXMarriageAdder()),\n",
    "    (\"next_bill\", NextBillAdder()),\n",
    "    (\"age_remove\", ColumnDropper('age'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (30000, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>marriage</th>\n",
       "      <th>pay_1</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>pay_5</th>\n",
       "      <th>pay_6</th>\n",
       "      <th>bill_amt1</th>\n",
       "      <th>bill_amt2</th>\n",
       "      <th>bill_amt3</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>gen_ageBin</th>\n",
       "      <th>gen_mar</th>\n",
       "      <th>pred_bill_amt0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20s</td>\n",
       "      <td>(2, 20s)</td>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>3909.683795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>20s</td>\n",
       "      <td>(2, 20s)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>2678.148995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>30s</td>\n",
       "      <td>(2, 30s)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>29177.529785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30s</td>\n",
       "      <td>(2, 30s)</td>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>46995.038110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>50s</td>\n",
       "      <td>(1, 50s)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>8605.584386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   limit_bal  gender  education  marriage  pay_1  pay_2  pay_3  pay_4  pay_5  \\\n",
       "0    20000.0       2          2         1      1      1      0      0      0   \n",
       "1   120000.0       2          2         2      0      1      0      0      0   \n",
       "2    90000.0       2          2         2      0      0      0      0      0   \n",
       "3    50000.0       2          2         1      0      0      0      0      0   \n",
       "4    50000.0       1          2         1      0      0      0      0      0   \n",
       "\n",
       "   pay_6  bill_amt1  bill_amt2  bill_amt3  bill_amt4  bill_amt5  bill_amt6  \\\n",
       "0      0     3913.0     3102.0      689.0        0.0        0.0        0.0   \n",
       "1      1     2682.0     1725.0     2682.0     3272.0     3455.0     3261.0   \n",
       "2      0    29239.0    14027.0    13559.0    14331.0    14948.0    15549.0   \n",
       "3      0    46990.0    48233.0    49291.0    28314.0    28959.0    29547.0   \n",
       "4      0     8617.0     5670.0    35835.0    20940.0    19146.0    19131.0   \n",
       "\n",
       "   pay_amt1  pay_amt2  pay_amt3  pay_amt4  pay_amt5  pay_amt6 age_bin  \\\n",
       "0       0.0     689.0       0.0       0.0       0.0       0.0     20s   \n",
       "1       0.0    1000.0    1000.0    1000.0       0.0    2000.0     20s   \n",
       "2    1518.0    1500.0    1000.0    1000.0    1000.0    5000.0     30s   \n",
       "3    2000.0    2019.0    1200.0    1100.0    1069.0    1000.0     30s   \n",
       "4    2000.0   36681.0   10000.0    9000.0     689.0     679.0     50s   \n",
       "\n",
       "  gen_ageBin gen_mar  pred_bill_amt0  \n",
       "0   (2, 20s)  (2, 1)     3909.683795  \n",
       "1   (2, 20s)  (2, 2)     2678.148995  \n",
       "2   (2, 30s)  (2, 2)    29177.529785  \n",
       "3   (2, 30s)  (2, 1)    46995.038110  \n",
       "4   (1, 50s)  (1, 1)     8605.584386  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_pipe_result(complex_pipe4, X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a CategoricalWarrior to 1-hot encode our categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with 1-hot encoded\n",
    "complex_pipe5 = Pipeline([\n",
    "    (\"age_bin\", AgeBinAdder()),\n",
    "    (\"gender_age_bin\", GenderXAgeBinAdder()),\n",
    "    (\"gender_marriage\", GenderXMarriageAdder()),\n",
    "    (\"next_bill\", NextBillAdder()),\n",
    "    (\"age_remove\", ColumnDropper('age')),\n",
    "    (\"1_hot\", CategoricalWarrior(['gender', 'education', 'marriage']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (30000, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit_bal</th>\n",
       "      <th>pay_1</th>\n",
       "      <th>pay_2</th>\n",
       "      <th>pay_3</th>\n",
       "      <th>pay_4</th>\n",
       "      <th>pay_5</th>\n",
       "      <th>pay_6</th>\n",
       "      <th>bill_amt1</th>\n",
       "      <th>bill_amt2</th>\n",
       "      <th>bill_amt3</th>\n",
       "      <th>bill_amt4</th>\n",
       "      <th>bill_amt5</th>\n",
       "      <th>bill_amt6</th>\n",
       "      <th>pay_amt1</th>\n",
       "      <th>pay_amt2</th>\n",
       "      <th>pay_amt3</th>\n",
       "      <th>pay_amt4</th>\n",
       "      <th>pay_amt5</th>\n",
       "      <th>pay_amt6</th>\n",
       "      <th>pred_bill_amt0</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>education_2</th>\n",
       "      <th>education_1</th>\n",
       "      <th>education_3</th>\n",
       "      <th>education_4</th>\n",
       "      <th>marriage_1</th>\n",
       "      <th>marriage_2</th>\n",
       "      <th>marriage_3</th>\n",
       "      <th>age_bin_20s</th>\n",
       "      <th>age_bin_30s</th>\n",
       "      <th>age_bin_40s</th>\n",
       "      <th>age_bin_50s</th>\n",
       "      <th>age_bin_60+</th>\n",
       "      <th>gen_ageBin_(1, '20s')</th>\n",
       "      <th>gen_ageBin_(1, '30s')</th>\n",
       "      <th>gen_ageBin_(1, '40s')</th>\n",
       "      <th>gen_ageBin_(1, '50s')</th>\n",
       "      <th>gen_ageBin_(1, '60+')</th>\n",
       "      <th>gen_ageBin_(2, '20s')</th>\n",
       "      <th>gen_ageBin_(2, '30s')</th>\n",
       "      <th>gen_ageBin_(2, '40s')</th>\n",
       "      <th>gen_ageBin_(2, '50s')</th>\n",
       "      <th>gen_ageBin_(2, '60+')</th>\n",
       "      <th>gen_mar_(1, 1)</th>\n",
       "      <th>gen_mar_(1, 2)</th>\n",
       "      <th>gen_mar_(1, 3)</th>\n",
       "      <th>gen_mar_(2, 1)</th>\n",
       "      <th>gen_mar_(2, 2)</th>\n",
       "      <th>gen_mar_(2, 3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3909.683795</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2678.148995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>29177.529785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>46995.038110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>8605.584386</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   limit_bal  pay_1  pay_2  pay_3  pay_4  pay_5  pay_6  bill_amt1  bill_amt2  \\\n",
       "0    20000.0      1      1      0      0      0      0     3913.0     3102.0   \n",
       "1   120000.0      0      1      0      0      0      1     2682.0     1725.0   \n",
       "2    90000.0      0      0      0      0      0      0    29239.0    14027.0   \n",
       "3    50000.0      0      0      0      0      0      0    46990.0    48233.0   \n",
       "4    50000.0      0      0      0      0      0      0     8617.0     5670.0   \n",
       "\n",
       "   bill_amt3  bill_amt4  bill_amt5  bill_amt6  pay_amt1  pay_amt2  pay_amt3  \\\n",
       "0      689.0        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1     2682.0     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2    13559.0    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3    49291.0    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4    35835.0    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   pay_amt4  pay_amt5  pay_amt6  pred_bill_amt0  gender_2  gender_1  \\\n",
       "0       0.0       0.0       0.0     3909.683795         1         0   \n",
       "1    1000.0       0.0    2000.0     2678.148995         1         0   \n",
       "2    1000.0    1000.0    5000.0    29177.529785         1         0   \n",
       "3    1100.0    1069.0    1000.0    46995.038110         1         0   \n",
       "4    9000.0     689.0     679.0     8605.584386         0         1   \n",
       "\n",
       "   education_2  education_1  education_3  education_4  marriage_1  marriage_2  \\\n",
       "0            1            0            0            0           1           0   \n",
       "1            1            0            0            0           0           1   \n",
       "2            1            0            0            0           0           1   \n",
       "3            1            0            0            0           1           0   \n",
       "4            1            0            0            0           1           0   \n",
       "\n",
       "   marriage_3  age_bin_20s  age_bin_30s  age_bin_40s  age_bin_50s  \\\n",
       "0           0            1            0            0            0   \n",
       "1           0            1            0            0            0   \n",
       "2           0            0            1            0            0   \n",
       "3           0            0            1            0            0   \n",
       "4           0            0            0            0            1   \n",
       "\n",
       "   age_bin_60+  gen_ageBin_(1, '20s')  gen_ageBin_(1, '30s')  \\\n",
       "0            0                      0                      0   \n",
       "1            0                      0                      0   \n",
       "2            0                      0                      0   \n",
       "3            0                      0                      0   \n",
       "4            0                      0                      0   \n",
       "\n",
       "   gen_ageBin_(1, '40s')  gen_ageBin_(1, '50s')  gen_ageBin_(1, '60+')  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      1                      0   \n",
       "\n",
       "   gen_ageBin_(2, '20s')  gen_ageBin_(2, '30s')  gen_ageBin_(2, '40s')  \\\n",
       "0                      1                      0                      0   \n",
       "1                      1                      0                      0   \n",
       "2                      0                      1                      0   \n",
       "3                      0                      1                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   gen_ageBin_(2, '50s')  gen_ageBin_(2, '60+')  gen_mar_(1, 1)  \\\n",
       "0                      0                      0               0   \n",
       "1                      0                      0               0   \n",
       "2                      0                      0               0   \n",
       "3                      0                      0               0   \n",
       "4                      0                      0               1   \n",
       "\n",
       "   gen_mar_(1, 2)  gen_mar_(1, 3)  gen_mar_(2, 1)  gen_mar_(2, 2)  \\\n",
       "0               0               0               1               0   \n",
       "1               0               0               0               1   \n",
       "2               0               0               0               1   \n",
       "3               0               0               1               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   gen_mar_(2, 3)  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_pipe_result(complex_pipe5, X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding & Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a StandardScaler to normalize our inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with 1-hot encoded\n",
    "# Pipeline with a StandardScaler\n",
    "complex_pipe6 = Pipeline([\n",
    "    (\"age_bin\", AgeBinAdder()),\n",
    "    (\"gender_age_bin\", GenderXAgeBinAdder()),\n",
    "    (\"gender_marriage\", GenderXMarriageAdder()),\n",
    "    (\"next_bill\", NextBillAdder()),\n",
    "    (\"age_remove\", ColumnDropper('age')),\n",
    "    (\"1_hot\", CategoricalWarrior(['gender', 'education', 'marriage'])),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (30000, 50)\n",
      "[[-1.13672015  1.84394071  2.39995869 -0.40419908 -0.36400938 -0.33135449\n",
      "  -0.33818882 -0.64250107 -0.64739923 -0.66799331 -0.67249727 -0.66305853\n",
      "  -0.65272422 -0.34194162 -0.22708564 -0.29680127 -0.30806256 -0.31413612\n",
      "  -0.29338206 -0.64264241  0.81016074 -0.81016074  1.06689977 -0.73837457\n",
      "  -0.44275183 -0.12588573  1.09377971 -1.06647132 -0.11281222  1.31303214\n",
      "  -0.74528643 -0.5002604  -0.26221495 -0.1069072  -0.38324492 -0.41253329\n",
      "  -0.30719909 -0.17756815 -0.07747568  1.78424128 -0.51816884 -0.35858507\n",
      "  -0.18694037 -0.0732252  -0.45737276 -0.52865999 -0.0696908   1.59446883\n",
      "  -0.67608338 -0.08828139]\n",
      " [-0.3659805  -0.54231679  2.39995869 -0.40419908 -0.36400938 -0.33135449\n",
      "   2.956928   -0.65921875 -0.66674657 -0.63925429 -0.62163594 -0.60622927\n",
      "  -0.59796638 -0.34194162 -0.21358766 -0.24000461 -0.24422965 -0.31413612\n",
      "  -0.18087821 -0.65937279  0.81016074 -0.81016074  1.06689977 -0.73837457\n",
      "  -0.44275183 -0.12588573 -0.91426088  0.93767172 -0.11281222  1.31303214\n",
      "  -0.74528643 -0.5002604  -0.26221495 -0.1069072  -0.38324492 -0.41253329\n",
      "  -0.30719909 -0.17756815 -0.07747568  1.78424128 -0.51816884 -0.35858507\n",
      "  -0.18694037 -0.0732252  -0.45737276 -0.52865999 -0.0696908  -0.62716811\n",
      "   1.4791075  -0.08828139]]\n"
     ]
    }
   ],
   "source": [
    "show_pipe_result(complex_pipe6, X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_pipelines = [complex_pipe1,\n",
    "                    complex_pipe2,\n",
    "                    complex_pipe3,\n",
    "                    complex_pipe4,\n",
    "                    complex_pipe5,\n",
    "                    complex_pipe6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the different classifiers that we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_models['log'] = log_clf = LogisticRegression(C=0.1, \n",
    "                             solver='liblinear',\n",
    "                             penalty='l2',\n",
    "                             class_weight='balanced', \n",
    "                             random_state=42, \n",
    "                             n_jobs=-1)\n",
    "dico_models['svm'] =  SVC(gamma='auto', C=1, class_weight='balanced')\n",
    "dico_models['tree'] = DecisionTreeClassifier(criterion='entropy', \n",
    "                                  random_state=42, \n",
    "                                 max_leaf_nodes=5,\n",
    "                                 class_weight='balanced')\n",
    "dico_models['forest'] = RandomForestClassifier(n_estimators=500, \n",
    "                                 max_leaf_nodes=10, \n",
    "                                 n_jobs=-1, \n",
    "                                 class_weight='balanced',\n",
    "                                random_state=42)\n",
    "\n",
    "dico_models['adaboost'] = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Pipelines consists of the following architecture:  \n",
    "  [Complex Pipeline, Classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dico_pipelined_models = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(complex_pipelines)):\n",
    "    for (name, model) in dico_models.items():\n",
    "        dico_pipelined_models[i][name] = Pipeline([\n",
    "            ('preproc', complex_pipelines[i]),\n",
    "            ('classifier', model)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('scaler',\n",
       "                                   StandardScaler(copy=True, with_mean=True,\n",
       "                                                  with_std=True))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=100,\n",
       "                                     multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                     random_state=42, solver='liblinear',\n",
       "                                     tol=0.0001, verbose=0, warm_start=False))],\n",
       "          verbose=False), 'svm': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('scaler',\n",
       "                                   StandardScaler(copy=True, with_mean=True,\n",
       "                                                  with_std=True))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "                      decision_function_shape='ovr', degree=3, gamma='auto',\n",
       "                      kernel='rbf', max_iter=-1, probability=False,\n",
       "                      random_state=None, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False), 'tree': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('scaler',\n",
       "                                   StandardScaler(copy=True, with_mean=True,\n",
       "                                                  with_std=True))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  DecisionTreeClassifier(class_weight='balanced',\n",
       "                                         criterion='entropy', max_depth=None,\n",
       "                                         max_features=None, max_leaf_nodes=5,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         presort=False, random_state=42,\n",
       "                                         splitter='best'))],\n",
       "          verbose=False), 'forest': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('scaler',\n",
       "                                   StandardScaler(copy=True, with_mean=True,\n",
       "                                                  with_std=True))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                         criterion='gini', max_depth=None,\n",
       "                                         max_features='auto', max_leaf_nodes=10,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=500, n_jobs=-1,\n",
       "                                         oob_score=False, random_state=42,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False), 'adaboost': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('scaler',\n",
       "                                   StandardScaler(copy=True, with_mean=True,\n",
       "                                                  with_std=True))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "                                     learning_rate=1.0, n_estimators=50,\n",
       "                                     random_state=None))],\n",
       "          verbose=False)}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_pipelined_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('age_bin', AgeBinAdder()),\n",
       "                                  ('gender_age_bin', GenderXAgeBinAdder()),\n",
       "                                  ('gender_marriage', GenderXMarriageAdder()),\n",
       "                                  ('next_bill', NextBillAdder()),\n",
       "                                  ('age_remove', ColumnDropper(column='age')),\n",
       "                                  ('1_hot',\n",
       "                                   CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                       'education',\n",
       "                                                                       'marriage']))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=100,\n",
       "                                     multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                                     random_state=42, solver='liblinear',\n",
       "                                     tol=0.0001, verbose=0, warm_start=False))],\n",
       "          verbose=False), 'svm': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('age_bin', AgeBinAdder()),\n",
       "                                  ('gender_age_bin', GenderXAgeBinAdder()),\n",
       "                                  ('gender_marriage', GenderXMarriageAdder()),\n",
       "                                  ('next_bill', NextBillAdder()),\n",
       "                                  ('age_remove', ColumnDropper(column='age')),\n",
       "                                  ('1_hot',\n",
       "                                   CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                       'education',\n",
       "                                                                       'marriage']))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "                      decision_function_shape='ovr', degree=3, gamma='auto',\n",
       "                      kernel='rbf', max_iter=-1, probability=False,\n",
       "                      random_state=None, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False), 'tree': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('age_bin', AgeBinAdder()),\n",
       "                                  ('gender_age_bin', GenderXAgeBinAdder()),\n",
       "                                  ('gender_marriage', GenderXMarriageAdder()),\n",
       "                                  ('next_bill', NextBillAdder()),\n",
       "                                  ('age_remove', ColumnDropper(column='age')),\n",
       "                                  ('1_hot',\n",
       "                                   CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                       'education',\n",
       "                                                                       'marriage']))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  DecisionTreeClassifier(class_weight='balanced',\n",
       "                                         criterion='entropy', max_depth=None,\n",
       "                                         max_features=None, max_leaf_nodes=5,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         presort=False, random_state=42,\n",
       "                                         splitter='best'))],\n",
       "          verbose=False), 'forest': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('age_bin', AgeBinAdder()),\n",
       "                                  ('gender_age_bin', GenderXAgeBinAdder()),\n",
       "                                  ('gender_marriage', GenderXMarriageAdder()),\n",
       "                                  ('next_bill', NextBillAdder()),\n",
       "                                  ('age_remove', ColumnDropper(column='age')),\n",
       "                                  ('1_hot',\n",
       "                                   CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                       'education',\n",
       "                                                                       'marriage']))],\n",
       "                           verbose=False)),\n",
       "                 ('cl...\n",
       "                  RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                         criterion='gini', max_depth=None,\n",
       "                                         max_features='auto', max_leaf_nodes=10,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=500, n_jobs=-1,\n",
       "                                         oob_score=False, random_state=42,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False), 'adaboost': Pipeline(memory=None,\n",
       "          steps=[('preproc',\n",
       "                  Pipeline(memory=None,\n",
       "                           steps=[('age_bin', AgeBinAdder()),\n",
       "                                  ('gender_age_bin', GenderXAgeBinAdder()),\n",
       "                                  ('gender_marriage', GenderXMarriageAdder()),\n",
       "                                  ('next_bill', NextBillAdder()),\n",
       "                                  ('age_remove', ColumnDropper(column='age')),\n",
       "                                  ('1_hot',\n",
       "                                   CategoricalWarrior(attribute_names=['gender',\n",
       "                                                                       'education',\n",
       "                                                                       'marriage']))],\n",
       "                           verbose=False)),\n",
       "                 ('classifier',\n",
       "                  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "                                     learning_rate=1.0, n_estimators=50,\n",
       "                                     random_state=None))],\n",
       "          verbose=False)}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_pipelined_models[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_classification_reports = defaultdict(dict)\n",
    "dico_confusion_matrices = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 0, Log\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      4673\n",
      "           1       0.48      0.57      0.52      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.78      0.77      0.78      6000\n",
      "\n",
      "Pipe 0, Svm\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84      4673\n",
      "           1       0.46      0.59      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "Pipe 0, Tree\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      4673\n",
      "           1       0.48      0.54      0.51      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.69      0.68      6000\n",
      "weighted avg       0.78      0.77      0.77      6000\n",
      "\n",
      "Pipe 0, Forest\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      4673\n",
      "           1       0.46      0.60      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "Pipe 0, Adaboost\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4673\n",
      "           1       0.62      0.33      0.43      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.73      0.64      0.66      6000\n",
      "weighted avg       0.78      0.81      0.78      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 1, Log\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      4673\n",
      "           1       0.48      0.57      0.52      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.78      0.77      0.78      6000\n",
      "\n",
      "Pipe 1, Svm\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84      4673\n",
      "           1       0.46      0.59      0.52      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.78      0.76      0.77      6000\n",
      "\n",
      "Pipe 1, Tree\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      4673\n",
      "           1       0.48      0.54      0.51      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.69      0.68      6000\n",
      "weighted avg       0.78      0.77      0.77      6000\n",
      "\n",
      "Pipe 1, Forest\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      4673\n",
      "           1       0.46      0.61      0.53      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.79      0.76      0.77      6000\n",
      "\n",
      "Pipe 1, Adaboost\n",
      "--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88      4673\n",
      "           1       0.62      0.31      0.42      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.73      0.63      0.65      6000\n",
      "weighted avg       0.78      0.81      0.78      6000\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-023a110bf22a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdico_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mpipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdico_pipelined_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pipe {}, {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1532\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "for i in range(len(complex_pipelines)):\n",
    "    for (name, model) in dico_models.items():\n",
    "        pipe = dico_pipelined_models[i][name]\n",
    "        pipe.fit(X_train, np.ravel(y_train))\n",
    "        print('Pipe {}, {}'.format(i, name.capitalize()))\n",
    "        print('--------')\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        dico_classification_reports[i][name] = classification_report(y_test, y_pred)\n",
    "        dico_confusion_matrices[i][name] = confusion_matrix(y_test, y_pred)\n",
    "        print(dico_classification_reports[i][name])\n",
    "        #print(dico_confusion_matrices[i][name])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(len(complex_pipelines)):\n",
    "    for (name, model) in dico_models.items():\n",
    "        pipe = dico_pipelined_models[i][name]\n",
    "        pipe.fit(X_train, np.ravel(y_train))\n",
    "        print(i, name.capitalize())\n",
    "        print('--------')\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        dico_classification_reports[i][name] = classification_report(y_test, y_pred)\n",
    "        dico_confusion_matrices[i][name] = confusion_matrix(y_test, y_pred)\n",
    "        print(dico_classification_reports[i][name])\n",
    "        #print(dico_confusion_matrices[i][name])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO Next"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Careful!\n",
    "Log doesn't take categorical: complex_pipeline2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* Use pipelines with XGBoost model (only the relevant Complex preprocessing pipelines ones!)\n",
    "ie: no need to scale\n",
    "* Use pipelines with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
