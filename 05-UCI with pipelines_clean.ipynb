{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- \n",
    "# UCI - Default from Credit Card Clients\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Dataset presentation\n",
    "\n",
    "This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n",
    "It can be found here:\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "There are 25 variables:\n",
    "\n",
    "* ID: ID of each client\n",
    "* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "* SEX: Gender (1=male, 2=female)\n",
    "* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "* MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "* AGE: Age in years\n",
    "* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
    "* PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "* PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "* PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "* PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "* PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
    "* default.payment.next.month: Default payment (1=yes, 0=no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Useful imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\boost',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\boost\\\\Library\\\\mingw-w64\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\boost\\\\Library\\\\usr\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\boost\\\\Library\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\boost\\\\Scripts',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs\\\\boost\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\condabin',\n",
       " 'C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin',\n",
       " 'C:\\\\ProgramData\\\\Oracle\\\\Java\\\\javapath',\n",
       " 'C:\\\\WINDOWS\\\\system32',\n",
       " 'C:\\\\WINDOWS',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\Wbem',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0',\n",
       " 'C:\\\\Program Files\\\\PuTTY',\n",
       " 'C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin',\n",
       " 'C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon',\n",
       " 'C:\\\\Program Files\\\\Git LFS',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\usr\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Scripts',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps',\n",
       " 'C:\\\\Users\\\\twang\\\\AppData\\\\Local\\\\Programs\\\\Git\\\\cmd',\n",
       " 'C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin',\n",
       " 'C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon']"
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PATH'].split(';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our Data easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'UCI_Credit_Card.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.load import load_raw_data\n",
    "from dataprep.load import load_data\n",
    "from dataprep.load import load_data_xy\n",
    "\n",
    "\n",
    "df = load_data(path)\n",
    "X_raw, y_raw = load_data_xy(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol for pipelined workflow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# * Pipeline for lowercasing\n",
    "* pipeline for re-labelling the mislabelled data\n",
    "\n",
    "* pipe for ageBins\n",
    "* pipe for gender x Marriage\n",
    "* pipe for gender x age\n",
    "* pipe for next month's bill\n",
    "---> One output: X_cat, que l'on normalise avec pipe=StandardScaler\n",
    "* pipe for 1-hot\n",
    "* pipe for scaling\n",
    "---> We get our second output X_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on se doit de définir les dictionnaires / classes que l'on va utiliser pour stocker les modèles, leurs scores selon toutes les métriques"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "models = []\n",
    "models.append(LogisticReg...)\n",
    "\n",
    "scores_accuracy={}\n",
    "scores_recall\n",
    "scores_auc\n",
    "features_importances={}\n",
    "chacun de ces dictionnaires contenant les performances du modèle: {'test': score_test, 'train': score_train}\n",
    "for model in models:\n",
    "    scores_accuracy{[model][train]} = accuracy_score(model.predict(X_test), y_test)\n",
    "    scores_accuracy{[model][test]} = accuracy(model.predict(X_train), y_train)\n",
    "    idem for recall, auc...\n",
    "    features_importances[model] = features_importanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, on pourra les capitalizer facilement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementary Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementary Pipelines are Pipelines that only do a little processing, such as adding / removing a single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex Pipelines are combinations of multiple Elementary Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Pipelines consists of the following architecture:  \n",
    "  [Complex Pipeline, Classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
